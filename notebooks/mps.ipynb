{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ea9a43",
   "metadata": {},
   "source": [
    "## Supervised Learning with ITensor: MPS for Classification\n",
    "\n",
    "[Supervised Learning with Quantum-Inspired Tensor Networks](https://arxiv.org/pdf/1605.05775), *NeurIPS 2016.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d003b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Statistics\n",
    "using ITensors, ITensorMPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19596849",
   "metadata": {},
   "source": [
    "*Why machine learning?* Tensor trains provide a linear model from a very large feature space, with only $O(N dm^2)$ parameters. \n",
    "\n",
    "*Goal:* Classify $8\\times 8$ grayscale images into two classes, can be extended to multi-class classification (e.g. MNIST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c104b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# synthetic data generation\n",
    "\n",
    "const H, W = 8, 8\n",
    "function make_bar(imgtype::Symbol; rng=Random.default_rng())\n",
    "    X = fill(0.0, H, W)\n",
    "    if imgtype == :vertical\n",
    "        j = rand(rng, 2:W-1)\n",
    "        X[:, j] .= 1.0\n",
    "    elseif imgtype == :horizontal\n",
    "        i = rand(rng, 2:H-1)\n",
    "        X[i, :] .= 1.0\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "function synth_dataset(n_per=200; rng=Random.default_rng())\n",
    "    Xv = [make_bar(:vertical; rng=rng) for _ in 1:n_per]\n",
    "    Xh = [make_bar(:horizontal; rng=rng) for _ in 1:n_per]\n",
    "    X = vcat(Xv, Xh)\n",
    "    y = vcat(fill(1, n_per), fill(0, n_per)) # 1 = vertical, 0 = horizontal\n",
    "    shuffle = randperm(rng, length(X))\n",
    "    return X[shuffle], y[shuffle]\n",
    "end\n",
    "\n",
    "X, y = synth_dataset(200)\n",
    "N = H * W # number of pixels, i.e. number of MPS sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb11283",
   "metadata": {},
   "source": [
    "*How are tensors useful?* Let $x = (x_1, x_2, \\ldots, x_N) \\in \\mathbb R^N$ be an input data point (image with $N$ pixels). A length $N$ binary vector has $2^N$ possible configurations, which is infeasible to work with directly. \n",
    "\n",
    "The trick is the *lift* each scalar $x_j$ to a small local feature vector and use a *tensor product* to build a structured, high-dimensional feature $\\Phi(x)$ that can be efficiently represented as a matrix product state (MPS).\n",
    "\n",
    "*Local feature map:*\n",
    "$$ \\phi: \\mathbb R \\to \\mathbb R^d,\\quad x_j \\mapsto \\phi(x_j) = \\left(\\phi_1(x_j), \\ldots, \\phi_d(x_j)\\right) $$\n",
    "We develop a tensor-product (rank-1, order-$N$ tensor) feature map:\n",
    "$$ \\Phi(x)_{s_1, s_2, \\ldots, s_N} = \\left[ \\phi(x_1) \\otimes \\cdots \\otimes \\phi(x_N) \\right]_{s_1, s_2, \\ldots, s_N} = \\prod_{j=1}^N \\phi_{s_j}(x_j),\\quad s_j \\in \\{1, 2, \\ldots, d\\} $$\n",
    "\n",
    "For grayscale images, a simple $d=2$ choice is\n",
    "$$ \\phi(x_j) = \\left( \\cos\\left(\\frac{\\pi}{2} x_j\\right), \\sin\\left(\\frac{\\pi}{2} x_j\\right) \\right) \\in \\mathbb R^2 $$\n",
    "which is *normalized*, i.e. $\\|\\phi(x_j)\\|_2 = 1$.\n",
    "\n",
    "*Why is this helpful?* $\\Phi(x)$ lives in a $d^N$-dimensional space, which is huge even for small $N$. However, the tensor-product structure allows us to represent $\\Phi(x)$ efficiently as an MPS with low bond dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b8a440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@inline feature(x::Real) = (cospi(0.5 * x), sinpi(0.5 * x)) # d = 2 feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32bb7d3",
   "metadata": {},
   "source": [
    "We classify data points with a *linear model* in the lifted space.\n",
    "$$ f(x) = W \\cdot \\Phi(x) = \\sum_{s_1, s_2, \\ldots, s_N} W_{s_1, s_2, \\ldots, s_N} \\Phi(x)_{s_1, s_2, \\ldots, s_N} $$\n",
    "where $W$ is a weight tensor of the same order and dimension as $\\Phi(x)$. To avoid working with the full $W$, we represent it as an MPS with low bond dimension $m$:\n",
    "$$ W_{s_1, s_2, \\ldots, s_N} = \\sum_{\\{\\alpha\\}} A^{[1]}_{s_1, \\alpha_1} A^{[2]}_{\\alpha_1, s_2, \\alpha_2} \\cdots A^{[N]}_{\\alpha_{N-1}, s_N} $$\n",
    "This reduces the number of parameters from $d^N$ to $O(N d m^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# local 2-dim indices for each pixel\n",
    "sites = siteinds(\"Qubit\", N) # qubit sites have dim 2\n",
    "\n",
    "# random weight MPS with bond dimension m\n",
    "m = 8\n",
    "Wmps = randomMPS(sites, m) # normalized random MPS (our weight tensor)\n",
    "\n",
    "# turn an image into 1-site feature Itensors matching 'sites'\n",
    "function image_to_features(img::AbstractMatrix{<:Real}, sites::Vector{<:Index})\n",
    "    feats = ITensor[]\n",
    "    v = vec(img)\n",
    "    for n in 1:length(v)\n",
    "        s = sites[n]\n",
    "        a, b = feature(v[n])\n",
    "        phi = ITensor(s)\n",
    "        phi[s => 1] = a\n",
    "        phi[s => 2] = b\n",
    "        push!(feats, phi)\n",
    "    end\n",
    "    return feats\n",
    "end\n",
    "\n",
    "# safe contraction helper (defined here for use in score)\n",
    "function _chain_contract(W::MPS, feats::Vector{ITensor})\n",
    "    @assert length(feats) == length(W)\n",
    "    T = W[1] * feats[1]\n",
    "    @inbounds for n in 2:length(feats)\n",
    "        Wn_contracted = W[n] * feats[n]  # contract physical index first\n",
    "        T = T * Wn_contracted              # then contract link indices\n",
    "    end\n",
    "    return T\n",
    "end\n",
    "\n",
    "# contract features with Wmps to get a scalar score f(x)\n",
    "function score(W::MPS, img::AbstractMatrix)\n",
    "    feats = image_to_features(img, siteinds(W))\n",
    "    T = _chain_contract(W, feats)\n",
    "    # T should be a scalar (rank-0 tensor) after contracting all indices\n",
    "    return scalar(T)\n",
    "end\n",
    "\n",
    "pred(s) = s > 0 ? 1 : 0 # binary prediction from score\n",
    "acc(W, Xs, ys) = mean(pred(score(W, x)) == y for (x, y) in zip(Xs, ys)) # accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57a790",
   "metadata": {},
   "source": [
    "To factor a big tensor $\\Psi_{s_1, \\ldots, s_N}$ to an MPS, we use a sequence of SVDs (tensor train SVD).\n",
    "\n",
    "The standard algorithm for this is as follows\n",
    "1. group $(s_1)$ and $(s_2, \\ldots, s_N)$\n",
    "2. SVD to get $U\\Sigma V^T$ and set $A^{[1]} = U\\Sigma$\n",
    "3. absorb $V^T$ into the next tensor and repeat until all tensors are extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b80d5",
   "metadata": {},
   "source": [
    "For binary labels $y_n \\in \\{0, 1\\}$, we use a *squared loss*\n",
    "$C(W) = \\frac{1}{2} \\sum_{n=1}^{N_T} (f(x_n) - y_n)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c172961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: initial acc\n",
      "│   acc(Wmps, X, y) = 0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:80\n",
      "┌ Info: epoch=1  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=2  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=3  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=2  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=3  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=4  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=5  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=4  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=5  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=6  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=7  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=8  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=9  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=10  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: final acc\n",
      "│   acc(Wmps, X, y) = 0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:82\n",
      "┌ Info: epoch=6  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=7  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=8  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=9  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: epoch=10  acc=0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:75\n",
      "┌ Info: final acc\n",
      "│   acc(Wmps, X, y) = 0.665\n",
      "└ @ Main /Users/aniket/Documents/university/siam/julia-tensors-worshop/notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:82\n"
     ]
    }
   ],
   "source": [
    "# one-site training loop\n",
    "\n",
    "Xφ = [image_to_features(x, sites) for x in X] # precompute features\n",
    "\n",
    "# contract features with MPS\n",
    "function chain_contract(W::MPS, feats::Vector{ITensor})\n",
    "    @assert length(feats) == length(W)\n",
    "    T = W[1] * feats[1]\n",
    "    @inbounds for n in 2:length(feats)\n",
    "        Wn_contracted = W[n] * feats[n]\n",
    "        T = T * Wn_contracted\n",
    "    end\n",
    "    return T\n",
    "end\n",
    "\n",
    "# left environment up to site j-1\n",
    "function left_env(W::MPS, feats::Vector{ITensor}, j::Int)\n",
    "    if j <= 1\n",
    "        return nothing\n",
    "    end\n",
    "    T = W[1] * feats[1]\n",
    "    @inbounds for n in 2:(j-1)\n",
    "        Wn_contracted = W[n] * feats[n]\n",
    "        T = T * Wn_contracted\n",
    "    end\n",
    "    return T\n",
    "end\n",
    "\n",
    "# right environment from site j+1 to N\n",
    "function right_env(W::MPS, feats::Vector{ITensor}, j::Int)\n",
    "    N = length(feats)\n",
    "    if j >= N\n",
    "        return nothing\n",
    "    end\n",
    "    T = W[N] * feats[N]\n",
    "    @inbounds for n in (N-1):-1:(j+1)\n",
    "        Wn_contracted = W[n] * feats[n]\n",
    "        T = Wn_contracted * T\n",
    "    end\n",
    "    return T\n",
    "end\n",
    "\n",
    "# one-site gradient step at site j using small mini-batch\n",
    "function update_site!(W::MPS, j; batch, lr=0.1)\n",
    "    G = zero(W[j])\n",
    "    for t in batch\n",
    "        feats = Xφ[t]\n",
    "        T_result = chain_contract(W, feats)\n",
    "        yhat = scalar(T_result)\n",
    "        e = (y[t] - yhat)\n",
    "        \n",
    "        L = left_env(W, feats, j)\n",
    "        R = right_env(W, feats, j)\n",
    "        ϕ = feats[j]\n",
    "        \n",
    "        contrib = (L === nothing ? ϕ : (L * ϕ))\n",
    "        contrib = (R === nothing ? contrib : (contrib * R))\n",
    "        G += (-e) * contrib\n",
    "    end\n",
    "    \n",
    "    W[j] = W[j] - lr * G\n",
    "    return W\n",
    "end\n",
    "\n",
    "# sweep training\n",
    "function train_one_site!(W::MPS; epochs=4, batchsize=128, rng=Random.default_rng())\n",
    "    idxs = collect(1:length(X))\n",
    "    for ep in 1:epochs\n",
    "        shuffle!(rng, idxs)\n",
    "        for j in 1:length(W)\n",
    "            batch = @view idxs[1:min(batchsize, length(idxs))]\n",
    "            update_site!(W, j; batch=batch)\n",
    "            circshift!(idxs, -min(batchsize, length(idxs)))\n",
    "        end\n",
    "        @info \"epoch=$ep  acc=$(acc(W, X, y))\"\n",
    "    end\n",
    "    return W\n",
    "end\n",
    "\n",
    "@info \"initial acc\" acc(Wmps, X, y)\n",
    "train_one_site!(Wmps; epochs=10, batchsize=32, rng=Random.default_rng())\n",
    "@info \"final acc\"   acc(Wmps, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac12ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "classification summary\n",
      "============================================================\n",
      "overall accuracy: 66.5% (266/400)\n",
      "\n",
      "vertical bars (class 1):\n",
      "  correct: 168 / 200\n",
      "  accuracy: 84.0%\n",
      "\n",
      "horizontal bars (class 0):\n",
      "  correct: 98 / 200\n",
      "  accuracy: 49.0%\n",
      "============================================================\n",
      "\n",
      "misclassified indices (first 10): [2, 5, 8, 11, 12, 16, 26, 28, 33, 38]\n"
     ]
    }
   ],
   "source": [
    "function classification_summary(W::MPS, Xs, ys)\n",
    "    predictions = [pred(score(W, x)) for x in Xs]\n",
    "    correct = predictions .== ys\n",
    "    \n",
    "    n_correct = sum(correct)\n",
    "    n_total = length(ys)\n",
    "    accuracy = n_correct / n_total\n",
    "    \n",
    "    # by class\n",
    "    vertical_indices = findall(ys .== 1)\n",
    "    horizontal_indices = findall(ys .== 0)\n",
    "    \n",
    "    vertical_correct = sum(correct[vertical_indices])\n",
    "    horizontal_correct = sum(correct[horizontal_indices])\n",
    "    \n",
    "    println(\"=\"^60)\n",
    "    println(\"classification summary\")\n",
    "    println(\"=\"^60)\n",
    "    println(\"overall accuracy: $(round(accuracy*100, digits=2))% ($n_correct/$n_total)\")\n",
    "    println()\n",
    "    println(\"vertical bars (class 1):\")\n",
    "    println(\"  correct: $vertical_correct / $(length(vertical_indices))\")\n",
    "    println(\"  accuracy: $(round(vertical_correct/length(vertical_indices)*100, digits=2))%\")\n",
    "    println()\n",
    "    println(\"horizontal bars (class 0):\")\n",
    "    println(\"  correct: $horizontal_correct / $(length(horizontal_indices))\")\n",
    "    println(\"  accuracy: $(round(horizontal_correct/length(horizontal_indices)*100, digits=2))%\")\n",
    "    println(\"=\"^60)\n",
    "    \n",
    "    # Show some misclassified examples\n",
    "    misclassified = findall(.!correct)\n",
    "    if length(misclassified) > 0\n",
    "        println(\"\\nmisclassified indices (first 10): \", misclassified[1:min(10, length(misclassified))])\n",
    "    else\n",
    "        println(\"\\nno misclassifications! perfect accuracy!\")\n",
    "    end\n",
    "end\n",
    "\n",
    "classification_summary(Wmps, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09526a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
